{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import os\n",
    "from simpletransformers.ner import NERArgs, NERModel\n",
    "import torch\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b1316dd5bf89b5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data for the model\n",
    "number = 1\n",
    "train_data_dir = 'train.tsv'\n",
    "eval_data_dir = 'train_a.tsv'\n",
    "labels = [\"B\", \":\", \";\", \",\", \".\", \"-\", \"...\", \"?\", \"!\"]\n",
    "model_type = \"bert\"\n",
    "model_name = \"dkleczek/bert-base-polish-cased-v1\"\n",
    "output_dir = f\"model_dir_{model_name}_{number}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f0e777cca962c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Changing data to DataFrame\n",
    "try:\n",
    "    train_data = pd.read_csv(train_data_dir, sep=\"\\t\", header=0, quoting=csv.QUOTE_NONE, on_bad_lines='skip', quotechar='\"')\n",
    "    evaluate_data = pd.read_csv(eval_data_dir, sep=\"\\t\", header=0, quoting=csv.QUOTE_NONE, on_bad_lines='skip', quotechar='\"')\n",
    "except Exception as e:\n",
    "    print(\"Error reading the data:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821c6ed51b547938",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Configurating model\n",
    "model_args = NERArgs()\n",
    "#model args\n",
    "model_args.model_type = model_type\n",
    "model_args.model_name = model_name\n",
    "model_args.early_stopping_metric = \"f1_weighted\"\n",
    "model_args.early_stopping_metric_minimize = False\n",
    "model_args.early_stopping_patience = 10 \n",
    "model_args.train_batch_size = 12\n",
    "model_args.output_dir = output_dir\n",
    "model_args.best_model_dir = os.path.join(output_dir,\"best_model\")\n",
    "model_args.num_train_epochs = 100\n",
    "model_args.use_cuda = torch.cuda.is_available() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f9c7e40225220c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating model\n",
    "model = NERModel(\n",
    "        model_type=model_type,\n",
    "        model_name=model_name,\n",
    "        labels=labels,\n",
    "        args=model_args,\n",
    "        use_cuda=torch.cuda.is_available()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Train the model on train data\n",
    "model.train_model(train_data, output_dir=output_dir,evaluate_data=evaluate_data, f1=sklearn.metrics.f1_score)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a29299626f16ef2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fda7b373e5a326c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on test-A data\n",
    "result, model_outputs, wrong_predictions = model.eval_model(evaluate_data)\n",
    "print(\"Evaluation Results:\", result)\n",
    "with open(f\"{model_type}_evaluation_result.txt\", 'w') as file:\n",
    "    for key, value in result.items():\n",
    "        file.write(f'{key}: {value}\\n')\n",
    "\n",
    "print(\"Results saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b6b2971903bbd8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predictions on test-D data\n",
    "input_path = 'in.tsv'\n",
    "with open(input_path, 'r', encoding='utf-8') as file:\n",
    "    to_predict = [line.strip().split('\\t')[1] for line in file if line.strip()]\n",
    "\n",
    "predictions, model_outputs_pred = model.predict(to_predict, split_on_space=True)\n",
    "\n",
    "output_path = f\"f{model_type}_predictions_output.txt\"\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as file:\n",
    "    for text, prediction in zip(to_predict, predictions):\n",
    "        file.write(f\"Text: {text}\\n\")\n",
    "        file.write(\"Predictions:\\n\")\n",
    "        for token, label in zip(text.split(), prediction):\n",
    "            file.write(f\"{label}\\n\")\n",
    "        file.write(\"\\n\")\n",
    "\n",
    "print(\"Predictions saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
